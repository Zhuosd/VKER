{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 用户基本信息\n",
    "unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "user_df = pd.read_csv('../../data/ml-1m/users.dat',\n",
    "                      sep='::',\n",
    "                      header=None,\n",
    "                      names=unames,\n",
    "                      engine='python')\n",
    "\n",
    "# 电影信息\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies_df = pd.read_csv('../../data/ml-1m/movies.dat',\n",
    "                        sep='::',\n",
    "                        header=None,\n",
    "                        names=mnames,\n",
    "                        engine='python',\n",
    "                        encoding='ISO-8859-1')\n",
    "\n",
    "# 评分信息\n",
    "rnames = ['user_id', 'movie_id', 'imdbId', 'timestamp']\n",
    "ratings_df = pd.read_csv('../../data/ml-1m/ratings.dat',\n",
    "                         sep='::',\n",
    "                         header=None,\n",
    "                         engine='python',\n",
    "                         names=rnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id gender  age  occupation    zip\n",
       "0           1      F    1          10  48067\n",
       "1           2      M   56          16  70072\n",
       "2           3      M   25          15  55117\n",
       "3           4      M   45           7  02460\n",
       "4           5      M   25          20  55455\n",
       "...       ...    ...  ...         ...    ...\n",
       "6035     6036      F   25          15  32603\n",
       "6036     6037      F   45           1  76006\n",
       "6037     6038      F   56           1  14706\n",
       "6038     6039      F   45           0  01060\n",
       "6039     6040      M   25           6  11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id                               title  \\\n",
       "0            1                    Toy Story (1995)   \n",
       "1            2                      Jumanji (1995)   \n",
       "2            3             Grumpier Old Men (1995)   \n",
       "3            4            Waiting to Exhale (1995)   \n",
       "4            5  Father of the Bride Part II (1995)   \n",
       "...        ...                                 ...   \n",
       "3878      3948             Meet the Parents (2000)   \n",
       "3879      3949          Requiem for a Dream (2000)   \n",
       "3880      3950                    Tigerland (2000)   \n",
       "3881      3951             Two Family House (2000)   \n",
       "3882      3952               Contender, The (2000)   \n",
       "\n",
       "                            genres  \n",
       "0      Animation|Children's|Comedy  \n",
       "1     Adventure|Children's|Fantasy  \n",
       "2                   Comedy|Romance  \n",
       "3                     Comedy|Drama  \n",
       "4                           Comedy  \n",
       "...                            ...  \n",
       "3878                        Comedy  \n",
       "3879                         Drama  \n",
       "3880                         Drama  \n",
       "3881                         Drama  \n",
       "3882                Drama|Thriller  \n",
       "\n",
       "[3883 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  imdbId  timestamp\n",
       "0              1      1193       5  978300760\n",
       "1              1       661       3  978302109\n",
       "2              1       914       3  978301968\n",
       "3              1      3408       4  978300275\n",
       "4              1      2355       5  978824291\n",
       "...          ...       ...     ...        ...\n",
       "1000204     6040      1091       1  956716541\n",
       "1000205     6040      1094       5  956704887\n",
       "1000206     6040       562       5  956704746\n",
       "1000207     6040      1096       4  956715648\n",
       "1000208     6040      1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图中的节点数：13410\n",
      "图中的边数：605849\n",
      "节点示例：[('user_1', {'type': 'user'}), ('gender_F', {'type': 'gender'}), ('age_1', {'type': 'age'}), ('occupation_10', {'type': 'occupation'}), ('zip_48067', {'type': 'zip'}), ('user_2', {'type': 'user'}), ('gender_M', {'type': 'gender'}), ('age_56', {'type': 'age'}), ('occupation_16', {'type': 'occupation'}), ('zip_70072', {'type': 'zip'})]\n",
      "边示例：[('user_1', 'gender_F', {'relation': 'has_gender'}), ('user_1', 'age_1', {'relation': 'has_age'}), ('user_1', 'occupation_10', {'relation': 'has_occupation'}), ('user_1', 'zip_48067', {'relation': 'has_zip'}), ('user_1', 'movie_1193', {'relation': 'rated', 'rating': 5}), ('user_1', 'movie_3408', {'relation': 'rated', 'rating': 4}), ('user_1', 'movie_2355', {'relation': 'rated', 'rating': 5}), ('user_1', 'movie_1287', {'relation': 'rated', 'rating': 5}), ('user_1', 'movie_2804', {'relation': 'rated', 'rating': 5}), ('user_1', 'movie_594', {'relation': 'rated', 'rating': 4})]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# 初始化空图\n",
    "G = nx.Graph()\n",
    "\n",
    "# ============ 添加用户节点和用户特征节点 ============\n",
    "for _, row in user_df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    gender = row['gender']\n",
    "    age = row['age']\n",
    "    occupation = row['occupation']\n",
    "    zip_code = row['zip']\n",
    "    \n",
    "    # 添加用户节点\n",
    "    G.add_node(f\"user_{user_id}\", type=\"user\")\n",
    "    \n",
    "    # 添加性别特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"gender_{gender}\"):\n",
    "        G.add_node(f\"gender_{gender}\", type=\"gender\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"gender_{gender}\", relation=\"has_gender\")\n",
    "    \n",
    "    # 添加年龄特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"age_{age}\"):\n",
    "        G.add_node(f\"age_{age}\", type=\"age\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"age_{age}\", relation=\"has_age\")\n",
    "    \n",
    "    # 添加职业特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"occupation_{occupation}\"):\n",
    "        G.add_node(f\"occupation_{occupation}\", type=\"occupation\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"occupation_{occupation}\", relation=\"has_occupation\")\n",
    "    \n",
    "    # 添加邮编特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"zip_{zip_code}\"):\n",
    "        G.add_node(f\"zip_{zip_code}\", type=\"zip\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"zip_{zip_code}\", relation=\"has_zip\")\n",
    "\n",
    "# ============ 添加电影节点及其类型 ============\n",
    "for _, row in movies_df.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    genres = row['genres'].split('|')\n",
    "    \n",
    "    # 添加电影节点\n",
    "    G.add_node(f\"movie_{movie_id}\", type=\"movie\")\n",
    "    \n",
    "    # 为每种类型添加类型节点，并连接到电影节点\n",
    "    for genre in genres:\n",
    "        if not G.has_node(f\"genre_{genre}\"):\n",
    "            G.add_node(f\"genre_{genre}\", type=\"genre\")\n",
    "        G.add_edge(f\"movie_{movie_id}\", f\"genre_{genre}\", relation=\"has_genre\")\n",
    "\n",
    "# ============ 添加用户-电影评分关系（仅保留高评分） ============\n",
    "for _, row in ratings_df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    movie_id = row['movie_id']\n",
    "    rating = row['imdbId']\n",
    "    \n",
    "    # 仅添加评分高于4的用户-电影边\n",
    "    if rating >= 4:\n",
    "        G.add_edge(f\"user_{user_id}\", f\"movie_{movie_id}\", relation=\"rated\", rating=rating)\n",
    "\n",
    "# 打印图的基本信息\n",
    "print(f\"图中的节点数：{G.number_of_nodes()}\")\n",
    "print(f\"图中的边数：{G.number_of_edges()}\")\n",
    "print(f\"节点示例：{list(G.nodes(data=True))[:10]}\")\n",
    "print(f\"边示例：{list(G.edges(data=True))[:10]}\")\n",
    "\n",
    "# 定义一个函数来生成三元组\n",
    "def generate_triples(G):\n",
    "    triples = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        # 获取节点的类型信息\n",
    "        u_type = G.nodes[u]['type']\n",
    "        v_type = G.nodes[v]['type']\n",
    "        \n",
    "        # 构建三元组\n",
    "        triple = (u, data['relation'], v)\n",
    "        triples.append(triple)\n",
    "    \n",
    "    return triples\n",
    "\n",
    "# 生成三元组\n",
    "triples = generate_triples(G)\n",
    "\n",
    "# 打印三元组个数\n",
    "print(f\"图中的三元组个数：{len(triples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21490be58964dfe89be03b65528afc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/13410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [40:18<00:00, 48.38s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [41:01<00:00, 49.24s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [40:32<00:00, 48.66s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [38:28<00:00, 46.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_1的嵌入： [ 0.27854162 -0.05543284  0.17488173  0.4709859  -0.50372684 -0.2635457\n",
      " -0.1901088   0.07926659 -0.06703474 -0.04729069 -0.09917847 -0.04797679\n",
      " -0.14226346 -0.40745646 -0.15916075 -0.4969948  -0.5953119  -0.02947216\n",
      " -0.10908683  0.02015037 -0.11641274  0.01189019 -0.26934153 -0.01210481\n",
      "  0.15266724  0.10402092 -0.11771433 -0.43442246  0.1285242  -0.2749632\n",
      "  0.03843929 -0.00389043 -0.25333497  0.252738   -0.10597965  0.3691169\n",
      "  0.00386108 -0.1576632  -0.07187559 -0.5028018   0.16807473 -0.01813983\n",
      " -0.30542555  0.2151913  -0.04081794 -0.03303645  0.47668704  0.19596347\n",
      "  0.01218809 -0.02246547  0.29087457 -0.10499363 -0.3265194   0.06418082\n",
      " -0.06660487 -0.4170587  -0.14665505  0.31318513 -0.1509345   0.5717627\n",
      " -0.49142522  0.08789222 -0.09353918 -0.68993026]\n",
      "模型已保存为 node2vec_model.model\n",
      "嵌入向量已保存为 node_embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "import pickle\n",
    "\n",
    "# 使用 node2vec 进行随机游走\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, p=1, q=1, workers=4)\n",
    "\n",
    "# 训练嵌入模型\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# 提取每个节点的嵌入向量\n",
    "embeddings = {str(node): model.wv[str(node)] for node in G.nodes()}\n",
    "\n",
    "# 查看用户1的嵌入\n",
    "print(\"user_1的嵌入：\", embeddings[\"user_1\"])\n",
    "\n",
    "model.save(\"node2vec_model.model\")\n",
    "print(\"模型已保存为 node2vec_model.model\")\n",
    "\n",
    "with open(\"node_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "print(\"嵌入向量已保存为 node_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 G 的节点和边的属性值统一转换为 int 类型\n",
    "for node, data in G.nodes(data=True):\n",
    "    for attr, value in data.items():\n",
    "        if isinstance(value, np.int64):  # 如果是 int64 类型，则转换为 int\n",
    "            data[attr] = int(value)\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    for attr, value in data.items():\n",
    "        if isinstance(value, np.int64):  # 如果是 int64 类型，则转换为 int\n",
    "            data[attr] = int(value)\n",
    "\n",
    "# 再进行 pyvis 的操作\n",
    "from pyvis.network import Network\n",
    "\n",
    "# 创建 Network 对象\n",
    "net = Network(notebook=True, cdn_resources='in_line')\n",
    "\n",
    "# 从 networkx 图导入数据\n",
    "net.from_nx(G)\n",
    "\n",
    "# 保存为 HTML 文件\n",
    "net.save_graph(\"knowledge_graph.html\")\n",
    "\n",
    "# 或者直接用 show 方法\n",
    "net.show(\"knowledge_graph.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**筛选数据操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据筛选和保存完成！\n"
     ]
    }
   ],
   "source": [
    "# 读取用户 ID 列表\n",
    "with open('../../data/movielens1m/user_list.txt', 'r') as f:\n",
    "    user_list = f.read().splitlines()\n",
    "    user_list = [int(uid.strip()) for uid in user_list if uid.strip().isdigit()]\n",
    "\n",
    "# 读取电影 ID 列表\n",
    "with open('../../data/movielens1m/item_list.txt', 'r') as f:\n",
    "    item_list = f.read().splitlines()\n",
    "    item_list = [int(mid.strip()) for mid in item_list if mid.strip().isdigit()]\n",
    "\n",
    "# 筛选 users.dat 中的用户信息\n",
    "filtered_user_df = user_df[user_df['user_id'].isin(user_list)]\n",
    "\n",
    "# 筛选 movies.dat 中的电影信息\n",
    "filtered_movies_df = movies_df[movies_df['movie_id'].isin(item_list)]\n",
    "\n",
    "# 筛选 ratings.dat 中的评分信息\n",
    "filtered_ratings_df = ratings_df[(ratings_df['user_id'].isin(user_list)) & (ratings_df['movie_id'].isin(item_list))]\n",
    "\n",
    "# 定义一个函数，用于将 DataFrame 直接保存为双冒号分隔的文件\n",
    "def save_with_double_colon(df, filename):\n",
    "    content = df.to_csv(sep='\\t', index=False, header=False)  # 使用制表符作为临时分隔符\n",
    "    content = content.replace('\\t', '::')  # 将制表符替换为双冒号\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "# 保存筛选后的数据\n",
    "save_with_double_colon(filtered_user_df, 'filtered_users.dat')\n",
    "save_with_double_colon(filtered_movies_df, 'filtered_movies.dat')\n",
    "save_with_double_colon(filtered_ratings_df, 'filtered_ratings.dat')\n",
    "\n",
    "print(\"数据筛选和保存完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**筛选后进行图谱的重新构建**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 用户基本信息\n",
    "unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "user_df = pd.read_csv('filtered_users.dat',\n",
    "                      sep='::',\n",
    "                      header=None,\n",
    "                      names=unames,\n",
    "                      engine='python')\n",
    "\n",
    "# 电影信息\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies_df = pd.read_csv('filtered_movies.dat',\n",
    "                        sep='::',\n",
    "                        header=None,\n",
    "                        names=mnames,\n",
    "                        engine='python',\n",
    "                        encoding='ISO-8859-1')\n",
    "\n",
    "# 评分信息\n",
    "rnames = ['user_id', 'movie_id', 'imdbId', 'timestamp']\n",
    "ratings_df = pd.read_csv('filtered_ratings.dat',\n",
    "                         sep='::',\n",
    "                         header=None,\n",
    "                         engine='python',\n",
    "                         names=rnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图中的节点数：10556\n",
      "图中的边数：550033\n",
      "节点示例：[('user_2', {'type': 'user'}), ('gender_M', {'type': 'gender'}), ('age_56', {'type': 'age'}), ('occupation_16', {'type': 'occupation'}), ('zip_70072', {'type': 'zip'}), ('user_3', {'type': 'user'}), ('age_25', {'type': 'age'}), ('occupation_15', {'type': 'occupation'}), ('zip_55117', {'type': 'zip'}), ('user_5', {'type': 'user'})]\n",
      "边示例：[('user_2', 'gender_M', {'relation': 'has_gender'}), ('user_2', 'age_56', {'relation': 'has_age'}), ('user_2', 'occupation_16', {'relation': 'has_occupation'}), ('user_2', 'zip_70072', {'relation': 'has_zip'}), ('user_2', 'movie_1357', {'relation': 'rated', 'rating': 5}), ('user_2', 'movie_3068', {'relation': 'rated', 'rating': 4}), ('user_2', 'movie_2194', {'relation': 'rated', 'rating': 4}), ('user_2', 'movie_648', {'relation': 'rated', 'rating': 4}), ('user_2', 'movie_2268', {'relation': 'rated', 'rating': 5}), ('user_2', 'movie_3468', {'relation': 'rated', 'rating': 5})]\n",
      "图中的三元组个数：550033\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# 初始化空图\n",
    "G = nx.Graph()\n",
    "\n",
    "# ============ 添加用户节点和用户特征节点 ============\n",
    "for _, row in user_df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    gender = row['gender']\n",
    "    age = row['age']\n",
    "    occupation = row['occupation']\n",
    "    zip_code = row['zip']\n",
    "    \n",
    "    # 添加用户节点\n",
    "    G.add_node(f\"user_{user_id}\", type=\"user\")\n",
    "    \n",
    "    # 添加性别特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"gender_{gender}\"):\n",
    "        G.add_node(f\"gender_{gender}\", type=\"gender\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"gender_{gender}\", relation=\"has_gender\")\n",
    "    \n",
    "    # 添加年龄特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"age_{age}\"):\n",
    "        G.add_node(f\"age_{age}\", type=\"age\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"age_{age}\", relation=\"has_age\")\n",
    "    \n",
    "    # 添加职业特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"occupation_{occupation}\"):\n",
    "        G.add_node(f\"occupation_{occupation}\", type=\"occupation\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"occupation_{occupation}\", relation=\"has_occupation\")\n",
    "    \n",
    "    # 添加邮编特征节点并连接到用户节点\n",
    "    if not G.has_node(f\"zip_{zip_code}\"):\n",
    "        G.add_node(f\"zip_{zip_code}\", type=\"zip\")\n",
    "    G.add_edge(f\"user_{user_id}\", f\"zip_{zip_code}\", relation=\"has_zip\")\n",
    "\n",
    "# ============ 添加电影节点及其类型 ============\n",
    "for _, row in movies_df.iterrows():\n",
    "    movie_id = row['movie_id']\n",
    "    genres = row['genres'].split('|')\n",
    "    \n",
    "    # 添加电影节点\n",
    "    G.add_node(f\"movie_{movie_id}\", type=\"movie\")\n",
    "    \n",
    "    # 为每种类型添加类型节点，并连接到电影节点\n",
    "    for genre in genres:\n",
    "        if not G.has_node(f\"genre_{genre}\"):\n",
    "            G.add_node(f\"genre_{genre}\", type=\"genre\")\n",
    "        G.add_edge(f\"movie_{movie_id}\", f\"genre_{genre}\", relation=\"has_genre\")\n",
    "\n",
    "# ============ 添加用户-电影评分关系（仅保留高评分） ============\n",
    "for _, row in ratings_df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    movie_id = row['movie_id']\n",
    "    rating = row['imdbId']\n",
    "    \n",
    "    # 仅添加评分高于4的用户-电影边\n",
    "    if rating >= 4:\n",
    "        G.add_edge(f\"user_{user_id}\", f\"movie_{movie_id}\", relation=\"rated\", rating=rating)\n",
    "\n",
    "# 打印图的基本信息\n",
    "print(f\"图中的节点数：{G.number_of_nodes()}\")\n",
    "print(f\"图中的边数：{G.number_of_edges()}\")\n",
    "print(f\"节点示例：{list(G.nodes(data=True))[:10]}\")\n",
    "print(f\"边示例：{list(G.edges(data=True))[:10]}\")\n",
    "\n",
    "# 定义一个函数来生成三元组\n",
    "def generate_triples(G):\n",
    "    triples = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        # 获取节点的类型信息\n",
    "        u_type = G.nodes[u]['type']\n",
    "        v_type = G.nodes[v]['type']\n",
    "        \n",
    "        # 构建三元组\n",
    "        triple = (u, data['relation'], v)\n",
    "        triples.append(triple)\n",
    "    \n",
    "    return triples\n",
    "\n",
    "# 生成三元组\n",
    "triples = generate_triples(G)\n",
    "\n",
    "# 打印三元组个数\n",
    "print(f\"图中的三元组个数：{len(triples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 G 的节点和边的属性值统一转换为 int 类型\n",
    "for node, data in G.nodes(data=True):\n",
    "    for attr, value in data.items():\n",
    "        if isinstance(value, np.int64):  # 如果是 int64 类型，则转换为 int\n",
    "            data[attr] = int(value)\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    for attr, value in data.items():\n",
    "        if isinstance(value, np.int64):  # 如果是 int64 类型，则转换为 int\n",
    "            data[attr] = int(value)\n",
    "\n",
    "# 再进行 pyvis 的操作\n",
    "from pyvis.network import Network\n",
    "\n",
    "# 创建 Network 对象\n",
    "net = Network(notebook=True, cdn_resources='in_line')\n",
    "\n",
    "# 从 networkx 图导入数据\n",
    "net.from_nx(G)\n",
    "\n",
    "# 保存为 HTML 文件\n",
    "net.save_graph(\"filtered_knowledge_graph.html\")\n",
    "\n",
    "# 或者直接用 show 方法\n",
    "# net.show(\"filtered_knowledge_graph.html\")\n",
    "\n",
    "\n",
    "subgraph_nodes = list(G.nodes)[:200]  # 仅取前100个节点\n",
    "subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "net = Network(notebook=True, cdn_resources='remote')\n",
    "net.from_nx(subgraph)\n",
    "net.show(\"filtered_knowledge_graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19804530aa624f94b422439e38560374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/10556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):  15%|█▍        | 11/75 [34:31<3:52:52, 218.33s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 使用 node2vec 进行随机游走\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m node2vec \u001b[38;5;241m=\u001b[39m \u001b[43mNode2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 训练嵌入模型\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m node2vec\u001b[38;5;241m.\u001b[39mfit(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/node2vec/node2vec.py:74\u001b[0m, in \u001b[0;36mNode2Vec.__init__\u001b[0;34m(self, graph, dimensions, walk_length, num_walks, p, q, weight_key, workers, sampling_strategy, quiet, temp_folder, seed)\u001b[0m\n\u001b[1;32m     71\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precompute_probabilities()\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_walks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/node2vec/node2vec.py:159\u001b[0m, in \u001b[0;36mNode2Vec._generate_walks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Split num_walks for each worker\u001b[39;00m\n\u001b[1;32m    157\u001b[0m num_walks_lists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_walks), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers)\n\u001b[0;32m--> 159\u001b[0m walk_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_generate_walks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_WALKS_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWALK_LENGTH_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEIGHBORS_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPROBABILITIES_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_TRAVEL_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_walks_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m walks \u001b[38;5;241m=\u001b[39m flatten(walk_results)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m walks\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "import pickle\n",
    "\n",
    "# 使用 node2vec 进行随机游走\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=200, num_walks=300, p=1, q=1, workers=4)\n",
    "\n",
    "# 训练嵌入模型\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "model.save(\"movie1m_model.model\")\n",
    "print(\"模型已保存为 movie1m_model.model\")\n",
    "\n",
    "# 提取每个节点的嵌入向量\n",
    "embeddings = {str(node): model.wv[str(node)] for node in G.nodes()}\n",
    "\n",
    "with open(\"movie1m_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "print(\"嵌入向量已保存为 movie1m_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 加载模型\n",
    "model = Word2Vec.load(\"movie1m_model.model\")\n",
    "print(\"模型加载成功\")\n",
    "\n",
    "# 初始化重新编号的用户和物品字典\n",
    "user_embeddings = {}\n",
    "item_embeddings = {}\n",
    "\n",
    "# 初始化用户和物品的编号映射表\n",
    "user_id_map = {}\n",
    "item_id_map = {}\n",
    "\n",
    "# 用于重新编号的计数器\n",
    "user_counter = 0\n",
    "item_counter = 0\n",
    "\n",
    "# 遍历模型中的所有节点\n",
    "for node in model.wv.key_to_index:\n",
    "    embedding = model.wv[node].tolist()\n",
    "    if node.startswith(\"user_\"):\n",
    "        # 重新编号用户\n",
    "        if node not in user_id_map:\n",
    "            user_id_map[node] = user_counter\n",
    "            user_counter += 1\n",
    "        # 使用新的编号存储用户的嵌入\n",
    "        user_embeddings[user_id_map[node]] = embedding\n",
    "    elif node.startswith(\"movie_\"):\n",
    "        # 重新编号物品\n",
    "        if node not in item_id_map:\n",
    "            item_id_map[node] = item_counter\n",
    "            item_counter += 1\n",
    "        # 使用新的编号存储物品的嵌入\n",
    "        item_embeddings[item_id_map[node]] = embedding\n",
    "\n",
    "# 保存用户嵌入为 JSON 文件\n",
    "with open(\"movie1m_user_embeddings.json\", \"w\") as user_file:\n",
    "    json.dump(user_embeddings, user_file, indent=4)\n",
    "print(\"重新编号的用户嵌入已保存为 movie1m_user_embeddings.json\")\n",
    "\n",
    "# 保存物品嵌入为 JSON 文件\n",
    "with open(\"movie1m_item_embeddings.json\", \"w\") as item_file:\n",
    "    json.dump(item_embeddings, item_file, indent=4)\n",
    "print(\"重新编号的物品嵌入已保存为 movie1m_item_embeddings.json\")\n",
    "\n",
    "# 保存用户和物品的编号映射\n",
    "with open(\"user_id_map.json\", \"w\") as user_map_file:\n",
    "    json.dump({k: v for k, v in user_id_map.items()}, user_map_file, indent=4)\n",
    "with open(\"item_id_map.json\", \"w\") as item_map_file:\n",
    "    json.dump({k: v for k, v in item_id_map.items()}, item_map_file, indent=4)\n",
    "print(\"用户和物品的编号映射已分别保存为 user_id_map.json 和 item_id_map.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def align_json_keys(source_file, target_file):\n",
    "    \"\"\"\n",
    "    对齐 source_file 中的键，使其与 target_file 中的键保持一致。\n",
    "    仅保留 source_file 中 target_file 存在的键。\n",
    "    \"\"\"\n",
    "    # 加载 target_file 的键\n",
    "    with open(target_file, \"r\") as f:\n",
    "        target_data = json.load(f)\n",
    "        target_keys = set(target_data.keys())\n",
    "    \n",
    "    # 加载 source_file 的数据\n",
    "    with open(source_file, \"r\") as f:\n",
    "        source_data = json.load(f)\n",
    "    \n",
    "    # 删除 source_file 中不在 target_file 中的键\n",
    "    original_keys = set(source_data.keys())\n",
    "    keys_to_remove = original_keys - target_keys\n",
    "    for key in keys_to_remove:\n",
    "        del source_data[key]\n",
    "    \n",
    "    # 保存对齐后的 source_file\n",
    "    with open(source_file, \"w\") as f:\n",
    "        json.dump(source_data, f, indent=4)\n",
    "    \n",
    "    print(f\"已对齐 {source_file} 的键，使其与 {target_file} 保持一致。\")\n",
    "    print(f\"删除了 {len(keys_to_remove)} 个不在 {target_file} 中的键。\")\n",
    "\n",
    "align_json_keys(\"movie1m_item_embeddings.json\", \"/Users/lizeyan/Desktop/Code/Voice-basedRS/VGCR-Code_New/src/Zeyan/emb_sum_movielens1m.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
